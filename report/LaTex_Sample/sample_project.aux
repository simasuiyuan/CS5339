\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\citation{freund1997decision}
\citation{blog,wiki}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{mult_weights}
\@writefile{toc}{\contentsline {section}{\numberline {2}Description of AdaBoost}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Preliminaries}{2}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Two examples of decision stumps, each applied to the same unlabeled data set. The points classified as positive are colored blue, and the points classified as negative are colored red. \relax }}{3}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:stumps}{{1}{3}{Two examples of decision stumps, each applied to the same unlabeled data set. The points classified as positive are colored blue, and the points classified as negative are colored red. \relax }{figure.caption.2}{}}
\newlabel{eq:fM}{{1}{3}{Preliminaries}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The Algorithm}{3}{subsection.2.2}\protected@file@percent }
\newlabel{eq:boost_theta}{{2}{3}{The Algorithm}{equation.2.2}{}}
\newlabel{eq:boost_w}{{3}{3}{The Algorithm}{equation.2.3}{}}
\newlabel{eq:Zm}{{4}{3}{The Algorithm}{equation.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of $\hat  {\alpha }_m$ as a function of $\hat  {\epsilon }_m$. \relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:alpha_plot}{{2}{4}{Plot of $\hat {\alpha }_m$ as a function of $\hat {\epsilon }_m$. \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Experimental results for AdaBoost on two data sets with $n=400$ data points and $M=50$ boosting iterations. The bottom-right of each example shows a color map of the function $f_M(\mathbf  {x})$, and taking its sign gives the predictions shown in the bottom-left. \relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:exp}{{3}{4}{Experimental results for AdaBoost on two data sets with $n=400$ data points and $M=50$ boosting iterations. The bottom-right of each example shows a color map of the function $f_M(\xv )$, and taking its sign gives the predictions shown in the bottom-left. \relax }{figure.caption.4}{}}
\newlabel{eq:update}{{6}{4}{The Algorithm}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Experimental Examples}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Mathematical Analysis}{5}{section.3}\protected@file@percent }
\newlabel{sec:math}{{3}{5}{Mathematical Analysis}{section.3}{}}
\newlabel{thm:main}{{1}{5}{}{thm.1}{}}
\newlabel{eq:main_result}{{7}{5}{}{equation.3.7}{}}
\newlabel{eq:boosting2}{{8}{5}{}{equation.3.8}{}}
\newlabel{eq:loss_exp}{{9}{5}{Mathematical Analysis}{equation.3.9}{}}
\newlabel{eq:step1}{{10}{5}{Mathematical Analysis}{equation.3.10}{}}
\newlabel{eq:step2}{{11}{5}{Mathematical Analysis}{equation.3.11}{}}
\citation{blog}
\citation{bishop2006pattern}
\citation{saberian2011multiclass}
\citation{scikit}
\citation{schapire1998boosting}
\citation{schapire1998boosting}
\newlabel{eq:Z_expression}{{12}{6}{Mathematical Analysis}{equation.3.12}{}}
\newlabel{eq:Z_expression2}{{13}{6}{Mathematical Analysis}{equation.3.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Extensions and Further Results}{6}{section.4}\protected@file@percent }
\newlabel{sec:ext}{{4}{6}{Extensions and Further Results}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Base Learners Beyond Decision Stumps}{6}{subsection.4.1}\protected@file@percent }
\newlabel{sec:base}{{4.1}{6}{Base Learners Beyond Decision Stumps}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Multi-Class Boosting}{6}{subsection.4.2}\protected@file@percent }
\newlabel{sec:multi}{{4.2}{6}{Multi-Class Boosting}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Characterization of the Test Error}{6}{subsection.4.3}\protected@file@percent }
\newlabel{sec:test_error}{{4.3}{6}{Characterization of the Test Error}{subsection.4.3}{}}
\bibstyle{plain}
\bibdata{refs}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proof of Theorem \ref  {thm:main} (AdaBoost Training Error Guarantee)}{9}{appendix.A}\protected@file@percent }
\newlabel{eq:step1a}{{14}{9}{Proof of Theorem \ref {thm:main} (AdaBoost Training Error Guarantee)}{equation.A.14}{}}
\newlabel{eq:step2a}{{15}{9}{Proof of Theorem \ref {thm:main} (AdaBoost Training Error Guarantee)}{equation.A.15}{}}
\newlabel{eq:Z_new}{{16}{9}{Proof of Theorem \ref {thm:main} (AdaBoost Training Error Guarantee)}{equation.A.16}{}}
\newlabel{eq:blah}{{19}{10}{Proof of Theorem \ref {thm:main} (AdaBoost Training Error Guarantee)}{equation.A.19}{}}
\gdef \@abspage@last{10}
