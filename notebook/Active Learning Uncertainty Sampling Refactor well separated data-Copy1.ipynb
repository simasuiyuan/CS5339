{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Overview\n",
    "## Step 0: Gather Data\n",
    "## Step 1: Split into Seed and Unlabelled Datasets\n",
    "## Step 2: Train the Model\n",
    "## Step 3: Choose unlabelled instances\n",
    "### 1. Determine the type of scenario:\n",
    "* [ ] Membership Query Synthesis\n",
    "* [ ] Stream-Based Selective Sampling\n",
    "* [X] Pool-Based sampling \n",
    "\n",
    "### 2. query strategy\n",
    "* [X] Uncertainty Sampling\n",
    "* [ ] Query-By-Committee\n",
    "* [ ] Expected Model Change\n",
    "* [ ] Expected Error Reduction\n",
    "* [ ] Variance Reduction\n",
    "* [ ] Density-Weighted Methods\n",
    "\n",
    "## Step 4: Stopping criteria\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.724597Z",
     "start_time": "2021-04-02T13:30:13.722466Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC, LinearSVC\n",
    "# from sklearn import svm\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from typing import Callable,List,Any\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import random\n",
    "# from sklearn.metrics import f1_score\n",
    "# from functools import wraps\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import nltk\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.744210Z",
     "start_time": "2021-04-02T13:30:13.742509Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Read data into a DataFrame\n",
    "# origdata = pd.read_csv('/etlstage/PE_joint/NUS_modules/CS5339/project/Iris.csv')\n",
    "# display(origdata.head())\n",
    "\n",
    "# # Read data into a DataFrame\n",
    "# titanic = pd.read_csv('/etlstage/PEE_joint/NUS_modules/CS5340/group_data/small.csv')\n",
    "# display(titanic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.751686Z",
     "start_time": "2021-04-02T13:30:13.748971Z"
    }
   },
   "outputs": [],
   "source": [
    "# def Initialization(clf,QueryStrategy):\n",
    "#     k1, k2 = 'PetalLengthCm', 'PetalWidthCm'\n",
    "#     data = origdata[[k1, k2, 'Species']].copy()\n",
    "\n",
    "#     X = data[[k1, k2]]\n",
    "#     y = data['Species']\n",
    "#     print('Classes:')\n",
    "#     # print(y.unique(), '\\n\\n\\n')\n",
    "\n",
    "#     y[y=='Iris-setosa'] = 0\n",
    "#     y[y=='Iris-versicolor'] = 1\n",
    "#     y[y=='Iris-virginica'] = 2\n",
    "\n",
    "#     plt.figure()\n",
    "#     setosa = y == 0\n",
    "#     versicolor = y == 1\n",
    "#     virginica = y == 2\n",
    "\n",
    "#     X1 = X[y != 0]\n",
    "#     y1 = y[y != 0]\n",
    "\n",
    "#     X1 = X1.reset_index(drop=True)\n",
    "#     y1 = y1.reset_index(drop=True)\n",
    "#     y1 -= 1\n",
    "#     y1 = y1.astype(dtype=np.uint8)\n",
    "    \n",
    "#     X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "#     X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "#     pool_datset = X_pool.copy()\n",
    "#     pool_datset['y'] = y_pool\n",
    "\n",
    "#     if \"QBC\" in QueryStrategy:\n",
    "#         clf0 = clf[0]\n",
    "#     else:\n",
    "#         clf0 = clf\n",
    "        \n",
    "#     clf0.fit(X1, y1)\n",
    "    \n",
    "#     if \"QBC\" in QueryStrategy:\n",
    "#         model = clf[0]\n",
    "#     else:\n",
    "#         model = clf\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(f\"f1_score = {f1_score(y_test, y_pred, average='macro')}\")\n",
    "\n",
    "#     print(clf0.coef_)\n",
    "#     print(clf0.intercept_)\n",
    "\n",
    "#     xmin, xmax = X1[k1].min(), X1[k1].max()\n",
    "#     ymin, ymax = X1[k2].min(), X1[k2].max()\n",
    "    \n",
    "#     stepx = (xmax - xmin)/99\n",
    "#     stepy = (ymax - ymin)/99\n",
    "\n",
    "\n",
    "#     a0, b0, c0 = clf0.coef_[0, 0], clf0.coef_[0, 1], clf0.intercept_\n",
    "\n",
    "#     # a*x + b*y + c = 0\n",
    "#     # y = -(a*x + c)/b\n",
    "\n",
    "#     lx0 = [xmin + stepx * i for i in range(100)]\n",
    "#     ly0 = [-(a0*lx0[i] + c0)/b0 for i in range(100)]\n",
    "    \n",
    "#     ly0min, ly0max = min(ly0), max(ly0)\n",
    "#     if (ymax - ymin) < (ly0max - ly0min):\n",
    "#         indx_rng = [ly0.index(i) for i in ly0 if (i<=ymax)&(i>=ymin)]\n",
    "#         print(indx_rng)\n",
    "#         lx0 = [lx0[i] for i in indx_rng]\n",
    "#         ly0 = [ly0[i] for i in indx_rng]\n",
    "#     plt.figure()\n",
    "\n",
    "#     # k1, k2 = k2, k1\n",
    "#     plt.title(\"using full dataset and SVC to plot true decision boundary\")\n",
    "#     # plt.scatter(x[k1][setosa], x[k2][setosa], c='r')\n",
    "#     plt.scatter(X1[k1][y1==0], X1[k2][y1==0], c='r')\n",
    "#     plt.scatter(X1[k1][y1==1], X1[k2][y1==1], c='c')\n",
    "\n",
    "#     plt.plot(lx0, ly0, c='m')\n",
    "\n",
    "#     plt.xlabel(k1)\n",
    "#     plt.ylabel(k2)\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "#     return  k1, k2, X1, y1,lx0,ly0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.757183Z",
     "start_time": "2021-04-02T13:30:13.752839Z"
    }
   },
   "outputs": [],
   "source": [
    "# def Initialization(clf,QueryStrategy):\n",
    "\n",
    "#     k1, k2 = 'feature1', 'feature2'\n",
    "#     data = dataset[[k1, k2, 'class']].copy()\n",
    "\n",
    "#     X = data[[k1, k2]]\n",
    "#     y = data['class']\n",
    "#     print('Classes:')\n",
    "#     print(y.unique(), '\\n\\n\\n')\n",
    "\n",
    "#     plt.figure()\n",
    "\n",
    "#     X1 = X\n",
    "#     y1 = y\n",
    "\n",
    "#     X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "#     X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "#     pool_datset = X_pool.copy()\n",
    "#     pool_datset['class'] = y_pool\n",
    "\n",
    "#     if \"QBC\" in QueryStrategy:\n",
    "#         clf0 = clf[0]\n",
    "#     else:\n",
    "#         clf0 = clf\n",
    "\n",
    "#     clf0.fit(X1, y1)\n",
    "\n",
    "#     if \"QBC\" in QueryStrategy:\n",
    "#         model = clf[0]\n",
    "#     else:\n",
    "#         model = clf\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(f\"f1_score = {f1_score(y_test, y_pred, average='macro')}\")\n",
    "\n",
    "#     print(clf0.coef_)\n",
    "#     print(clf0.intercept_)\n",
    "\n",
    "#     xmin, xmax = X1[k1].min(), X1[k1].max()\n",
    "#     ymin, ymax = X1[k2].min(), X1[k2].max()\n",
    "\n",
    "#     stepx = (xmax - xmin)/99\n",
    "#     stepy = (ymax - ymin)/99\n",
    "\n",
    "\n",
    "#     a0, b0, c0 = clf0.coef_[0, 0], clf0.coef_[0, 1], clf0.intercept_\n",
    "\n",
    "#     # a*x + b*y + c = 0\n",
    "#     # y = -(a*x + c)/b\n",
    "\n",
    "#     lx0 = [xmin + stepx * i for i in range(100)]\n",
    "#     ly0 = [-(a0*lx0[i] + c0)/b0 for i in range(100)]\n",
    "\n",
    "#     ly0min, ly0max = min(ly0), max(ly0)\n",
    "#     if (ymax - ymin) < (ly0max - ly0min):\n",
    "#         indx_rng = [ly0.index(i) for i in ly0 if (i<=ymax)&(i>=ymin)]\n",
    "#         print(indx_rng)\n",
    "#         lx0 = [lx0[i] for i in indx_rng]\n",
    "#         ly0 = [ly0[i] for i in indx_rng]\n",
    "#     plt.figure()\n",
    "\n",
    "#     # k1, k2 = k2, k1\n",
    "#     plt.title(\"using full dataset and SVC to plot true decision boundary\")\n",
    "#     # plt.scatter(x[k1][setosa], x[k2][setosa], c='r')\n",
    "#     plt.scatter(X1[k1][y1==0], X1[k2][y1==0], c='r')\n",
    "#     plt.scatter(X1[k1][y1==1], X1[k2][y1==1], c='c')\n",
    "\n",
    "#     plt.plot(lx0, ly0, c='m')\n",
    "\n",
    "#     plt.xlabel(k1)\n",
    "#     plt.ylabel(k2)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     return  k1, k2, X1, y1,lx0,ly0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.762577Z",
     "start_time": "2021-04-02T13:30:13.759172Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# X, y = make_classification(n_samples=1000,n_features=2, n_redundant=0, n_informative=2,\n",
    "#                            random_state=4124235443, n_clusters_per_class=1,class_sep=0.5)#3423\n",
    "\n",
    "# # X1, Y1 = make_classification(n_features=2, n_redundant=0, n_informative=1,\n",
    "# #                              n_clusters_per_class=1)\n",
    "\n",
    "# dataset = pd.DataFrame(data=X, columns=['feature1','feature2'])\n",
    "# dataset['class'] = y\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.767643Z",
     "start_time": "2021-04-02T13:30:13.763688Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = SVC(kernel='linear',probability=True)\n",
    "\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(clf,'Least_Confident')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.775371Z",
     "start_time": "2021-04-02T13:30:13.768793Z"
    }
   },
   "outputs": [],
   "source": [
    "# class active_learning_base():\n",
    "#     def __init__(self, QueryStrategy):\n",
    "#         self.QueryStrategy = QueryStrategy\n",
    "#         self.Query_Strategy_Frameworks={}\n",
    "        \n",
    "#     def add_Query_Strategy(self, cls):\n",
    "#         def decorator(func):\n",
    "#             self.Query_Strategy_Frameworks[func.__name__] = func\n",
    "#             @wraps(func)\n",
    "#             def wrapper(self, *args, **kwargs): \n",
    "#                 return func(*args, **kwargs)\n",
    "#             setattr(cls, func.__name__, wrapper)\n",
    "#             return func\n",
    "#         return decorator\n",
    "    \n",
    "#     def error_logging(self,clf,X_test,y_test):\n",
    "#         if \"QBC\" in self.QueryStrategy:\n",
    "#             model = clf[0]\n",
    "#         else:\n",
    "#             model = clf\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         matrix = confusion_matrix(y_test, y_pred)\n",
    "#         #print(matrix)\n",
    "#         #print(matrix[0][1]+matrix[1][0])\n",
    "#         return f1_score(y_test, y_pred, average='macro'), matrix[0][1]+matrix[1][0]\n",
    "        \n",
    "#     def plot_svm(self,clf, train_indexes, unknown_indexes, new_index = False, title = False, name = False):\n",
    "#         X_train = X_pool.iloc[train_indexes]\n",
    "#         y_train = y_pool.iloc[train_indexes]\n",
    "\n",
    "#         X_unk = X_pool.iloc[unknown_indexes]\n",
    "#         # y_unk = y_pool.iloc[unknown_indexes]\n",
    "\n",
    "#         if new_index:\n",
    "#             X_new = X_pool.iloc[new_index]\n",
    "            \n",
    "#         if \"QBC\" in self.QueryStrategy:\n",
    "#             model = clf[0]\n",
    "#         else:\n",
    "#             model = clf\n",
    "\n",
    "#         a, b, c = model.coef_[0, 0], model.coef_[0, 1], model.intercept_\n",
    "        \n",
    "#        # print(a, b, c)\n",
    "#         # a*x + b*y + c = 0\n",
    "#         # y = -(a*x + c)/b\n",
    "#         xmin, xmax = X_pool[k1].min(), X_pool[k1].max()\n",
    "#         ymin, ymax = X_pool[k2].min(), X_pool[k2].max()\n",
    "#         stepx = (xmax - xmin)/99\n",
    "#         stepy = (ymax - ymin)/99\n",
    "        \n",
    "#         lx = [xmin + stepx * i for i in range(100)]\n",
    "#         ly = [-(a*lx[i] + c)/b for i in range(100)]\n",
    "\n",
    "#         lymin, lymax = min(ly), max(ly)\n",
    "#         if (ymax - ymin) < (lymax - lymin):\n",
    "#             indx_rng = [ly.index(i) for i in ly if (i<=ymax)&(i>=ymin)]\n",
    "#             #print(indx_rng)\n",
    "#             lx = [lx[i] for i in indx_rng]\n",
    "#             ly = [ly[i] for i in indx_rng]\n",
    "#         plt.figure()\n",
    "\n",
    "#         fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "#         # plt.scatter(x[k1][setosa], x[k2][setosa], c='r')\n",
    "#         plt.scatter(X_unk[k1], X_unk[k2], c='k', marker = '.', label=\"unlablled\")\n",
    "#         plt.scatter(X_train[k1][y_train==0], X_train[k2][y_train==0], c='r', marker = 'o', label=\"lablled\")\n",
    "#         plt.scatter(X_train[k1][y_train==1], X_train[k2][y_train==1], c='c', marker = 'o', label=\"lablled\")\n",
    "\n",
    "#         plt.plot(lx0, ly0, '--', c='g', label=\"True DB\")    \n",
    "#         plt.plot(lx, ly, c='m', label=\"new DB\")\n",
    "\n",
    "#         if new_index:\n",
    "#             plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125, label=\"new lablled\")\n",
    "#             plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125, label=\"new lablled\")\n",
    "#             plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125, label=\"new lablled\")\n",
    "#             plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125, label=\"new lablled\")\n",
    "#             plt.scatter(X_new[k1], X_new[k2], c='y', marker=\"*\", s=125, label=\"new lablled\")\n",
    "\n",
    "#         if title:\n",
    "#             plt.title(title)\n",
    "\n",
    "#         plt.xlabel(k1)\n",
    "#         plt.ylabel(k2)\n",
    "#         handles, labels = plt.gca().get_legend_handles_labels()\n",
    "#         by_label = dict(zip(labels, handles))\n",
    "#         plt.legend(by_label.values(), by_label.keys())\n",
    "        \n",
    "#         if title in [\"Iteration 5\",\"Iteration 20\",\"Iteration 200\",\"Iteration 550\"]:\n",
    "#             plt.savefig(f'/etlstage/PEE_joint/NUS_modules/CS5339/project/image/{self.QueryStrategy}_{title}.png')\n",
    "#         plt.show()\n",
    "    \n",
    "#     def active_learner(self,clf,train_size,\n",
    "#                        X_pool,y_pool,X_test,y_test,\n",
    "#                        budget,if_plot=False):#def active_learner(self, **fit_kwargs,)\n",
    "#         score = []\n",
    "#         no_of_err = []\n",
    "#         train_indexes=[]\n",
    "#         init_cls_size = int(train_size/len(set(y_pool)))\n",
    "#         # generate a cold start\n",
    "        \n",
    "#         for cls in set(y_pool):\n",
    "#             X_pool_cls = X_pool.iloc[y_pool[(y_pool==cls)].index]\n",
    "#             if cls==0:\n",
    "#                 train_indexes.append(X_pool_cls[(X_pool_cls[k1] == X_pool_cls[k1].max())].index[0])\n",
    "#             else:\n",
    "#                 train_indexes.append(X_pool_cls[(X_pool_cls[k1] == X_pool_cls[k1].min())].index[0])\n",
    "# #         for cls in set(y_pool):\n",
    "# #             for i in range(init_cls_size):\n",
    "# #                 train_indexes.append(y_pool[(y_pool==cls)].index[i])\n",
    "                \n",
    "#         unknown_indexes = [unlabeled_idx for unlabeled_idx in list(range(len(X_pool))) if unlabeled_idx not in train_indexes]\n",
    "#         X_train = X_pool.iloc[train_indexes]\n",
    "#         y_train = y_pool.iloc[train_indexes]\n",
    "        \n",
    "#         if \"QBC\" in self.QueryStrategy:\n",
    "#             for model in clf:\n",
    "#                 model.fit(X_train, y_train)\n",
    "#         else:\n",
    "#             clf.fit(X_train, y_train)\n",
    "        \n",
    "#         if if_plot:\n",
    "#             title = \"Cold start\"\n",
    "#             self.plot_svm(clf, train_indexes, unknown_indexes, False, title)\n",
    "            \n",
    "        \n",
    "#         f1_score,mis_cls = self.error_logging(clf,X_test,y_test,)\n",
    "#         score.append(f1_score)\n",
    "#         no_of_err.append(mis_cls)\n",
    "        \n",
    "#         n = self.Query_Strategy_Frameworks[self.QueryStrategy](clf,X_pool.iloc[unknown_indexes],unknown_indexes)\n",
    "#         unknown_indexes.remove(n)\n",
    "#         if if_plot:\n",
    "#             title = \"Iteration 0\"\n",
    "#             self.plot_svm(clf, train_indexes, unknown_indexes, n, title)\n",
    "            \n",
    "#         f1_score,mis_cls = self.error_logging(clf,X_test,y_test,)\n",
    "#         score.append(f1_score)\n",
    "#         no_of_err.append(mis_cls)\n",
    "        \n",
    "#         for i in range(budget):\n",
    "#             train_indexes.append(n)\n",
    "#             X_train = X_pool.iloc[train_indexes]\n",
    "#             y_train = y_pool.iloc[train_indexes]\n",
    "            \n",
    "#             if \"QBC\" in self.QueryStrategy:\n",
    "#                 for model in clf:\n",
    "#                     model.fit(X_train, y_train)\n",
    "#             else:\n",
    "#                 clf.fit(X_train, y_train)\n",
    "            \n",
    "#             n = self.Query_Strategy_Frameworks[self.QueryStrategy](clf,X_pool.iloc[unknown_indexes],unknown_indexes)\n",
    "#             unknown_indexes.remove(n)\n",
    "#             if if_plot:\n",
    "#                 title = \"Iteration \"+str(i+1)\n",
    "#                 self.plot_svm(clf, train_indexes, unknown_indexes, n, title)\n",
    "#             f1_score,mis_cls = self.error_logging(clf,X_test,y_test,)\n",
    "#             score.append(f1_score)\n",
    "#             no_of_err.append(mis_cls)\n",
    "#         return train_indexes,clf,score,no_of_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Split into Seed and Unlabelled Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.784846Z",
     "start_time": "2021-04-02T13:30:13.783113Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = SVC(kernel='linear',probability=True)\n",
    "\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(clf,'Least_Confident')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.790743Z",
     "start_time": "2021-04-02T13:30:13.789120Z"
    }
   },
   "outputs": [],
   "source": [
    "# score_bench_mark = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Train the Model \n",
    "clf = SVC(kernel='linear')\n",
    "# Step 3: Choose unlabelled instances\n",
    "## 1. Determine the type of scenario: Pool-Based sampling\n",
    "## 2. query strategy\n",
    "## 2.0 Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.805784Z",
     "start_time": "2021-04-02T13:30:13.803976Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf = SVC(kernel='linear',probability=True)\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(clf,'Random_sample')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())\n",
    "\n",
    "\n",
    "# active_learning = active_learning_base('Random_sample')\n",
    "\n",
    "# @active_learning.add_Query_Strategy(active_learning_base)\n",
    "# def Random_sample(clf,X_train,unknown_indexes):\n",
    "#     return random.sample(unknown_indexes, 1)[0]\n",
    "\n",
    "# train_indexes,clf,score,no_of_err = active_learning.active_learner(clf,2,X_pool,y_pool,X_test,y_test,len(y_pool)-3,if_plot=True)\n",
    "# print(score)\n",
    "# print(no_of_err)\n",
    "# score_bench_mark['Random_sample_f1'] =  score\n",
    "# score_bench_mark['Random_sample_err'] =  no_of_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Uncertainty Sampling\n",
    "### 2.1.1 least confident\n",
    "### $x^*_{LC} = argmax_x(1-P_{\\theta}(\\hat{y}|x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.899981Z",
     "start_time": "2021-04-02T13:30:13.898074Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf = SVC(kernel='linear',probability=True)\n",
    "\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(clf,'Least_Confident')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())\n",
    "\n",
    "# active_learning = active_learning_base('Least_Confident')\n",
    "\n",
    "# @active_learning.add_Query_Strategy(active_learning_base)\n",
    "# def Least_Confident(clf,X_train,unknown_indexes):\n",
    "#     LC_matrix = [1- max(P_hat) for P_hat in clf.predict_proba(X_train)]\n",
    "#     LC = np.argmax(LC_matrix)\n",
    "#     return unknown_indexes[LC]\n",
    "\n",
    "# train_indexes,clf,score,no_of_err = active_learning.active_learner(clf,2,X_pool,y_pool,X_test,y_test,len(y_pool)-3,if_plot=True)\n",
    "# print(score)\n",
    "# print(no_of_err)\n",
    "# score_bench_mark['Least_Confident_f1'] =  score\n",
    "# score_bench_mark['Least_Confident_err'] =  no_of_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 margin sampling\n",
    "### $x^*_{M} = argmax_x(P_{\\theta}(\\hat{y_1}|x)-P_{\\theta}(\\hat{y_2}|x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:13.989953Z",
     "start_time": "2021-04-02T13:30:13.987885Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf = SVC(kernel='linear',probability=True)\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(clf,'Margin_Sampling')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())\n",
    "\n",
    "# active_learning = active_learning_base('Margin_Sampling')\n",
    "\n",
    "# @active_learning.add_Query_Strategy(active_learning_base)\n",
    "# def Margin_Sampling(clf,X_train,unknown_indexes):\n",
    "#     MS_matrix = []\n",
    "#     for P_hat in clf.predict_proba(X_train):\n",
    "#         P_hat_max = max(P_hat)\n",
    "#         P_hat = np.delete(P_hat, np.argmax(P_hat))\n",
    "#         P_hat_sec = max(P_hat)\n",
    "#         MS_matrix = [P_hat_max - P_hat_sec]\n",
    "#     MS = np.argmin(MS_matrix)\n",
    "#     return unknown_indexes[MS]\n",
    "\n",
    "# train_indexes,clf,score,no_of_err = active_learning.active_learner(clf,2,X_pool,y_pool,X_test,y_test,len(y_pool)-3,if_plot=True)\n",
    "# score_bench_mark['Margin_Sampling_f1'] =  score\n",
    "# score_bench_mark['Margin_Sampling_err'] =  no_of_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3  general uncertainty sampling: entropy\n",
    "### $x^*_{H} = argmax_x(-\\sum_{i}P_{\\theta}(y_i|x)logP_{\\theta}(y_i|x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.074020Z",
     "start_time": "2021-04-02T13:30:14.071958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf = SVC(kernel='linear',probability=True)\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(clf,'sample_by_entropy')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())\n",
    "\n",
    "# active_learning = active_learning_base('sample_by_entropy')\n",
    "\n",
    "# @active_learning.add_Query_Strategy(active_learning_base)\n",
    "# def sample_by_entropy(clf,X_train,unknown_indexes):\n",
    "#     entropy_matrix = []\n",
    "#     y_prob = clf.predict_proba(X_train)\n",
    "#     for y in y_prob:\n",
    "#         entropy = 0.0\n",
    "#         for r in y:\n",
    "#             if r!=0:\n",
    "#                 entropy += r * np.log(r)\n",
    "#         entropy_matrix+=[-entropy]\n",
    "#     return unknown_indexes[np.argmax(entropy_matrix)]\n",
    "\n",
    "# train_indexes,clf,score,no_of_err = active_learning.active_learner(clf,2,X_pool,y_pool,X_test,y_test,len(y_pool)-3,if_plot=True)\n",
    "# score_bench_mark['sample_by_entropy_f1'] =  score\n",
    "# score_bench_mark['sample_by_entropy_err'] =  no_of_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Query-By-Committee\n",
    "\n",
    "### 2.2.1  Query-By-Committee: vote entropy\n",
    "### $x^*_{H} = argmax_x(-\\sum_{i}\\frac{V(y_i)}{C}log\\frac{V(y_i)}{C})$\n",
    "* $V(y_i)$: the number of “votes” that a label receives from among the committee members’ predictions\n",
    "* $C$: committee size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.088741Z",
     "start_time": "2021-04-02T13:30:14.087049Z"
    }
   },
   "outputs": [],
   "source": [
    "# from nltk.classify.scikitlearn import SklearnClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# # from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.163764Z",
     "start_time": "2021-04-02T13:30:14.161548Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# committee =[LogisticRegression(),SVC(kernel='linear',probability=True),\n",
    "#             RandomForestClassifier(bootstrap=True),DecisionTreeClassifier()]\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(committee,'QBC_vote_entropy')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/?labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())\n",
    "\n",
    "\n",
    "# active_learning = active_learning_base('QBC_vote_entropy')\n",
    "\n",
    "# @active_learning.add_Query_Strategy(active_learning_base)\n",
    "# def QBC_vote_entropy(committee,X_train,unknown_indexes):\n",
    "#     num_classes = len(committee[0].classes_)\n",
    "#     C = len(committee)\n",
    "#     y_preds = []\n",
    "#     votes = np.zeros((num_classes,len(X_train)))\n",
    "#     for model in committee:\n",
    "#         y_preds = np.fromiter(model.predict(X_train), dtype=np.int)\n",
    "#         for y_idx in range(len(y_preds)):\n",
    "#             votes[y_preds[y_idx]][y_idx]+=1\n",
    "#     votes = votes/C\n",
    "#     entropy_matrix = []\n",
    "#     for vote in votes.T:\n",
    "#         __entropy = 0.0\n",
    "#         for r in vote:\n",
    "#             if r != 0:\n",
    "#                 __entropy += r * np.log(r)\n",
    "#         entropy_matrix+=[-__entropy]\n",
    "#     return unknown_indexes[np.argmax(entropy_matrix)]\n",
    "\n",
    "\n",
    "# train_indexes,clf,score,no_of_err = active_learning.active_learner(committee,2,X_pool,y_pool,X_test,y_test,len(y_pool)-3,if_plot=True)\n",
    "# score_bench_mark['QBC_vote_entropy_f1'] =  score\n",
    "# score_bench_mark['QBC_vote_entropy_f1_err'] =  no_of_err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.237761Z",
     "start_time": "2021-04-02T13:30:14.235235Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# committee =[LogisticRegression(),SVC(kernel='linear',probability=True),\n",
    "#             RandomForestClassifier(bootstrap=True),DecisionTreeClassifier()]\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(committee,'QBC_kl_divergence')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/?labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())\n",
    "\n",
    "\n",
    "\n",
    "# active_learning = active_learning_base('QBC_kl_divergence')\n",
    "\n",
    "# @active_learning.add_Query_Strategy(active_learning_base)\n",
    "# def QBC_kl_divergence(committee,X_train,unknown_indexes):\n",
    "#     num_classes = len(committee[0].classes_)\n",
    "#     C = len(committee)\n",
    "#     y_probs = []\n",
    "#     y_probs_C = None\n",
    "#     committee_votes = None\n",
    "    \n",
    "#     for model in committee:\n",
    "#         y_probs += [model.predict_proba(X_train)]\n",
    "#         if y_probs_C is None:\n",
    "#             y_probs_C = model.predict_proba(X_train)\n",
    "#         else:\n",
    "#             y_probs_C = y_probs_C + model.predict_proba(X_train)\n",
    "            \n",
    "#     for y_prob in y_probs:\n",
    "#         votes = []\n",
    "#         for i_idx in range(len(y_prob)):\n",
    "#             vote = 0.0\n",
    "#             PCy_i = y_probs_C[i_idx]\n",
    "#             Py_i = y_prob[i_idx]\n",
    "#             for r_idx in range(len(PCy_i)):\n",
    "#                 if Py_i[r_idx]!=0:\n",
    "#                     vote += Py_i[r_idx] * (np.log(Py_i[r_idx])-np.log(PCy_i[r_idx]))\n",
    "#             votes+=[vote]\n",
    "#         if committee_votes is None:\n",
    "#             committee_votes = np.array(votes)\n",
    "#         else:\n",
    "#             committee_votes = committee_votes + np.array(votes)\n",
    "#     #print(committee_votes)\n",
    "#     committee_votes = np.array(committee_votes)/C\n",
    "#     return unknown_indexes[np.argmax(committee_votes)]\n",
    "\n",
    "# train_indexes,clf,score,no_of_err = active_learning.active_learner(committee,2,X_pool,y_pool,X_test,y_test,len(y_pool)-3,if_plot=True)\n",
    "# score_bench_mark['QBC_kl_divergence_f1'] =  score\n",
    "# score_bench_mark['QBC_kl_divergence_err'] =  no_of_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.314018Z",
     "start_time": "2021-04-02T13:30:14.311969Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = SVC(kernel='linear',probability=True)\n",
    "# k1, k2, X1, y1,lx0,ly0 = Initialization(clf,'Random_sample')\n",
    "\n",
    "# X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=2)\n",
    "# X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "# pool_datset = X_pool.copy()\n",
    "# pool_datset['y'] = y_pool\n",
    "\n",
    "# print(f\"X_pool,y_pool: trainning data pool for unlabelled/labelled data ; size = {len(X_pool)}\")\n",
    "# print(f\"X_test,y_test: test data; size = {len(X_test)}\")\n",
    "# display(pool_datset.head())\n",
    "\n",
    "\n",
    "# active_learning = active_learning_base('Random_sample')\n",
    "\n",
    "# @active_learning.add_Query_Strategy(active_learning_base)\n",
    "# def Random_sample(clf,X_train,unknown_indexes):\n",
    "#     random.seed(54315)\n",
    "#     return random.sample(unknown_indexes, 1)[0]\n",
    "\n",
    "# train_indexes,clf,score,no_of_err = active_learning.active_learner(clf,2,X_pool,y_pool,X_test,y_test,len(y_pool)-3,if_plot=True)\n",
    "# print(score)\n",
    "# print(random.getstate())\n",
    "# score_bench_mark['Random_sample'] =  score\n",
    "# score_bench_mark['Random_sample_f1'] =  score\n",
    "# score_bench_mark['Random_sample_err'] =  no_of_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.319613Z",
     "start_time": "2021-04-02T13:30:14.315490Z"
    }
   },
   "outputs": [],
   "source": [
    "# score_bench_mark.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.325159Z",
     "start_time": "2021-04-02T13:30:14.320995Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(score_bench_mark).reset_index()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.330396Z",
     "start_time": "2021-04-02T13:30:14.326519Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(score_bench_mark).reset_index()\n",
    "# # df = df.round(2)\n",
    "# from scipy.ndimage.filters import gaussian_filter1d\n",
    "# for col in df.columns[1:]:\n",
    "#     #df[col+'_MA'] = df.loc[:,col].rolling(window=5).mean()\n",
    "#     df[col+'_smooth'] = gaussian_filter1d(df[col], sigma=50)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.335968Z",
     "start_time": "2021-04-02T13:30:14.331541Z"
    }
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px \n",
    "# df1 = pd.melt(df, id_vars=['index'], value_vars=[col for col in list(df.columns) if col[-4:]==\"_err\"]).reset_index().rename(columns={\"index\": \"Iteration\", \"value\": \"err\",\"variable\":\"Query_Strategy\"})\n",
    "# fig = px.line(df1, x='Iteration', y='err', color='Query_Strategy')\n",
    "# # df2 = pd.melt(df, id_vars=['index'], value_vars=list(df.columns)[7:])\n",
    "# # fig = px.line(df2, x='index', y='value', color='variable')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T13:30:14.341377Z",
     "start_time": "2021-04-02T13:30:14.337338Z"
    }
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px \n",
    "# df1 = pd.melt(df, id_vars=['index'], value_vars=[col for col in list(df.columns) if col[-11:]==\"_err_smooth\"]).reset_index().rename(columns={\"index\": \"Iteration\", \"value\": \"err_smooth\",\"variable\":\"Query_Strategy\"})\n",
    "# fig = px.line(df1, x='Iteration', y='err_smooth', color='Query_Strategy')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f10ds_spark_py36",
   "language": "python",
   "name": "f10ds_spark_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
